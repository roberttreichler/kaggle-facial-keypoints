{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********************************\n",
    "      Import Data + Packages\n",
    "*********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create working directory\n",
    "import os#Miscellaneous operating system interfaces\n",
    "os.chdir(r'C:\\\\Users\\\\rtreichl\\\\Documents\\\\competitions\\\\telstra')  #working directory\n",
    "\n",
    "#%matplotlib inline allows graphics to show below each cell (or graphics in line)\n",
    "# for some reason, %matplotlib inline won't work if comments are made in the same cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd #munging and wrangling\n",
    "import numpy as np  #for arrays, etc.\n",
    "import matplotlib.pyplot as plt #graphs/plots\n",
    "\n",
    "#Regression Multi-Output\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor #aka as Extremely Randomized Trees\n",
    "\n",
    "#Dimensionality Reduction \n",
    "from sklearn.decomposition import RandomizedPCA #to create eigenface\n",
    "\n",
    "#Model Selection -> Cross Validation\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "#Model Selection -> Metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Model Selectin -> Parameter selection\n",
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use dataframes for EDA\n",
    "ftrain = pd.read_csv('training.csv')\n",
    "ftest  = pd.read_csv('test.csv')\n",
    "flookup= pd.read_csv('IdLookupTable.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********************************\n",
    "EDA / Preprocessing / Data Preparation\n",
    "*********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop -> column has no purpose\n",
    "flookup= flookup.drop(['Location'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train descriptive stats\n",
    "train_describe=ftrain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_eye_center_x            7039\n",
       "left_eye_center_y            7039\n",
       "right_eye_center_x           7036\n",
       "right_eye_center_y           7036\n",
       "left_eye_inner_corner_x      2271\n",
       "left_eye_inner_corner_y      2271\n",
       "left_eye_outer_corner_x      2267\n",
       "left_eye_outer_corner_y      2267\n",
       "right_eye_inner_corner_x     2268\n",
       "right_eye_inner_corner_y     2268\n",
       "right_eye_outer_corner_x     2268\n",
       "right_eye_outer_corner_y     2268\n",
       "left_eyebrow_inner_end_x     2270\n",
       "left_eyebrow_inner_end_y     2270\n",
       "left_eyebrow_outer_end_x     2225\n",
       "left_eyebrow_outer_end_y     2225\n",
       "right_eyebrow_inner_end_x    2270\n",
       "right_eyebrow_inner_end_y    2270\n",
       "right_eyebrow_outer_end_x    2236\n",
       "right_eyebrow_outer_end_y    2236\n",
       "nose_tip_x                   7049\n",
       "nose_tip_y                   7049\n",
       "mouth_left_corner_x          2269\n",
       "mouth_left_corner_y          2269\n",
       "mouth_right_corner_x         2270\n",
       "mouth_right_corner_y         2270\n",
       "mouth_center_top_lip_x       2275\n",
       "mouth_center_top_lip_y       2275\n",
       "mouth_center_bottom_lip_x    7016\n",
       "mouth_center_bottom_lip_y    7016\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show specifically the count of instances/records by variable\n",
    "#2140 output variables are without null values\n",
    "train_describe.ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2140\n"
     ]
    }
   ],
   "source": [
    "#delete instances where missing outputs\n",
    "ftrain= ftrain.dropna()\n",
    "print(len(ftrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2140\n",
      "(2140, 31)\n"
     ]
    }
   ],
   "source": [
    "#create horizontal images and predictors\n",
    "#double training set by flipping image horizontally\n",
    "#point right to left (or vice versa)\n",
    "# change output variable x-coordinates by (96 - x)\n",
    "\n",
    "#this code works but does not improve predictive performance\n",
    "\n",
    "train_temp=[]\n",
    "train_temp0=[]\n",
    "train_temp=pd.DataFrame(columns=ftrain.columns)\n",
    "\n",
    "for i in range(len(ftrain)):\n",
    "    image=ftrain['Image'].iloc[i]\n",
    "    image=image.split()\n",
    "    image=np.array(image).reshape(96,96) # reshape to 9216 x 9216\n",
    "#    image=image.astype(float)  #float\n",
    "    image=image[:,::-1]  #flip the image horizontally\n",
    "    image=image.reshape(1,9216) #put back as 1d array\n",
    "    image_str=\"\"\n",
    "    for zz in range(len(image[0])):\n",
    "        image_str=image_str + str(image[0,zz]) + \" \"\n",
    "    train_temp0=pd.DataFrame({\n",
    "            'Image'                    : [image_str],\n",
    "            'left_eye_center_x'        : [((96-ftrain['right_eye_center_x'].iloc[i]))],\n",
    "            'left_eye_center_y'        : [((ftrain['right_eye_center_y'].iloc[i]))],\n",
    "            'right_eye_center_x'       : [((96-ftrain['left_eye_center_x'].iloc[i]))],\n",
    "            'right_eye_center_y'       : [((ftrain['left_eye_center_y'].iloc[i]))],\n",
    "            'left_eye_inner_corner_x'  : [((96-ftrain['right_eye_inner_corner_x'].iloc[i]))],\n",
    "            'left_eye_inner_corner_y'  : [((ftrain['right_eye_inner_corner_y'].iloc[i]))],\n",
    "            'left_eye_outer_corner_x'  : [((96-ftrain['right_eye_outer_corner_x'].iloc[i]))],\n",
    "            'left_eye_outer_corner_y'  : [((ftrain['right_eye_outer_corner_y'].iloc[i]))],\n",
    "            'right_eye_inner_corner_x' : [((96-ftrain['left_eye_inner_corner_x'].iloc[i]))],\n",
    "            'right_eye_inner_corner_y' : [((ftrain['left_eye_inner_corner_y'].iloc[i]))],\n",
    "            'right_eye_outer_corner_x' : [((96-ftrain['left_eye_outer_corner_x'].iloc[i]))],\n",
    "            'right_eye_outer_corner_y' : [((ftrain['left_eye_outer_corner_y'].iloc[i]))],\n",
    "            'left_eyebrow_inner_end_x' : [((96-ftrain['right_eyebrow_inner_end_x'].iloc[i]))],\n",
    "            'left_eyebrow_inner_end_y' : [((ftrain['right_eyebrow_inner_end_y'].iloc[i]))],\n",
    "            'left_eyebrow_outer_end_x' : [((96-ftrain['right_eyebrow_outer_end_x'].iloc[i]))],\n",
    "            'left_eyebrow_outer_end_y' : [((ftrain['right_eyebrow_outer_end_y'].iloc[i]))],\n",
    "            'right_eyebrow_inner_end_x': [((96-ftrain['left_eyebrow_inner_end_x'].iloc[i]))],\n",
    "            'right_eyebrow_inner_end_y': [((ftrain['left_eyebrow_inner_end_y'].iloc[i]))],\n",
    "            'right_eyebrow_outer_end_x': [((96-ftrain['left_eyebrow_outer_end_x'].iloc[i]))],\n",
    "            'right_eyebrow_outer_end_y': [((ftrain['left_eyebrow_outer_end_y'].iloc[i]))],\n",
    "            'nose_tip_x'               : [((96-ftrain['nose_tip_x'].iloc[i]))],\n",
    "            'nose_tip_y'               : [((ftrain['nose_tip_y'].iloc[i]))],\n",
    "            'mouth_left_corner_x'      : [((96-ftrain['mouth_right_corner_x'].iloc[i]))],\n",
    "            'mouth_left_corner_y'      : [((ftrain['mouth_right_corner_y'].iloc[i]))],\n",
    "            'mouth_right_corner_x'     : [((96-ftrain['mouth_left_corner_x'].iloc[i]))],\n",
    "            'mouth_right_corner_y'     : [((ftrain['mouth_left_corner_y'].iloc[i]))],\n",
    "            'mouth_center_top_lip_x'   : [((96-ftrain['mouth_center_top_lip_x'].iloc[i]))],\n",
    "            'mouth_center_top_lip_y'   : [((ftrain['mouth_center_top_lip_y'].iloc[i]))],\n",
    "            'mouth_center_bottom_lip_x': [((96-ftrain['mouth_center_bottom_lip_x'].iloc[i]))],\n",
    "            'mouth_center_bottom_lip_y': [((ftrain['mouth_center_bottom_lip_y'].iloc[i]))],\n",
    "        })\n",
    "    train_temp=train_temp.append(train_temp0)\n",
    "\n",
    "print(len(train_temp))\n",
    "print(train_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4280\n",
      "(4280, 31)\n"
     ]
    }
   ],
   "source": [
    "#combine original train data with horizontal train data \n",
    "ftrain=ftrain.append(train_temp)\n",
    "print(len(ftrain))\n",
    "print(ftrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columntitles=['left_eye_center_x',\n",
    " 'left_eye_center_y',\n",
    " 'left_eye_inner_corner_x',\n",
    " 'left_eye_inner_corner_y',\n",
    " 'left_eye_outer_corner_x',\n",
    " 'left_eye_outer_corner_y',\n",
    " 'left_eyebrow_inner_end_x',\n",
    " 'left_eyebrow_inner_end_y',\n",
    " 'left_eyebrow_outer_end_x',\n",
    " 'left_eyebrow_outer_end_y',\n",
    " 'mouth_center_bottom_lip_x',\n",
    " 'mouth_center_bottom_lip_y',\n",
    " 'mouth_center_top_lip_x',\n",
    " 'mouth_center_top_lip_y',\n",
    " 'mouth_left_corner_x',\n",
    " 'mouth_left_corner_y',\n",
    " 'mouth_right_corner_x',\n",
    " 'mouth_right_corner_y',\n",
    " 'nose_tip_x',\n",
    " 'nose_tip_y',\n",
    " 'right_eye_center_x',\n",
    " 'right_eye_center_y',\n",
    " 'right_eye_inner_corner_x',\n",
    " 'right_eye_inner_corner_y',\n",
    " 'right_eye_outer_corner_x',\n",
    " 'right_eye_outer_corner_y',\n",
    " 'right_eyebrow_inner_end_x',\n",
    " 'right_eyebrow_inner_end_y',\n",
    " 'right_eyebrow_outer_end_x',\n",
    " 'right_eyebrow_outer_end_y',\n",
    "              'Image']\n",
    "ftrain=ftrain.reindex(columns=columntitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4280\n",
      "(4280, 9216)\n"
     ]
    }
   ],
   "source": [
    "#convert train-1 to array with 9216 width\n",
    "x_train=ftrain['Image'].str.split()\n",
    "x_train=np.vstack(x_train)\n",
    "x_train=x_train.astype(float)\n",
    "print(len(x_train))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4280\n",
      "(4280, 30)\n"
     ]
    }
   ],
   "source": [
    "#create output variable train-1\n",
    "#create output variables\n",
    "y_train=np.array(ftrain.ix[:,0:30])\n",
    "\n",
    "print(len(y_train))\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1783\n",
      "(1783, 9216)\n"
     ]
    }
   ],
   "source": [
    "#create test set\n",
    "x_test=ftest['Image'].str.split()\n",
    "x_test=np.vstack(x_test)\n",
    "x_test=x_test.astype(float)\n",
    "print(len(x_test))\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************************************\n",
    "          Additional EDA\n",
    "*************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#further inspection of plots that outly the cluster show people with glasses\n",
    "#'left_eye_center_x', 'left_eye_center_y'\n",
    "#visualize predictor look for outliers\n",
    "fig1=plt.figure()\n",
    "ax=fig1.add_subplot(1,1,1)\n",
    "ax.scatter(ftrain['left_eye_center_x'],ftrain['left_eye_center_y'],color=\"red\")\n",
    "ax.scatter(ftrain['right_eye_center_x'],ftrain['right_eye_center_y'],color=\"green\")\n",
    "ax.scatter(ftrain['mouth_center_top_lip_x'],ftrain['mouth_center_top_lip_y'],color=\"blue\")\n",
    "plt.ylim([0,96])\n",
    "plt.xlim([0,96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'left_eye_inner_corner_x'left_eye_inner_corner_y'\n",
    "#visualize predictor look for outliers\n",
    "fig1=plt.figure()\n",
    "ax=fig1.add_subplot(1,1,1)\n",
    "ax.scatter(ftrain['left_eye_inner_corner_x'],ftrain['left_eye_inner_corner_y'], color=\"red\")\n",
    "ax.scatter(ftrain['right_eye_inner_corner_x'],ftrain['right_eye_inner_corner_y'], color=\"green\")\n",
    "ax.scatter(ftrain['mouth_left_corner_x'],ftrain['mouth_left_corner_y'],color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'left_eyebrow_inner_end_x','left_eyebrow_inner_end_y'\n",
    "#visualize predictor look for outliers\n",
    "fig1=plt.figure()\n",
    "ax=fig1.add_subplot(1,1,1)\n",
    "ax.scatter(ftrain['left_eyebrow_inner_end_x'],ftrain['left_eyebrow_inner_end_y'],color=\"red\")\n",
    "ax.scatter(ftrain['right_eyebrow_inner_end_x'],ftrain['right_eyebrow_inner_end_y'],color=\"green\")\n",
    "ax.scatter(ftrain['mouth_center_bottom_lip_x'],ftrain['mouth_center_bottom_lip_y'],color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'left_eye_outer_corner_x', 'left_eye_outer_corner_y', \n",
    "#visualize predictor look for outliers        \n",
    "fig1=plt.figure()\n",
    "ax=fig1.add_subplot(1,1,1)\n",
    "ax.scatter(ftrain['left_eye_outer_corner_x'],ftrain['left_eye_outer_corner_y'],color=\"red\")\n",
    "ax.scatter(ftrain['right_eye_outer_corner_x'],ftrain['right_eye_outer_corner_y'],color=\"green\")\n",
    "ax.scatter(ftrain['mouth_right_corner_x'],ftrain['mouth_right_corner_y'], color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'left_eyebrow_outer_end_x','left_eyebrow_outer_end_y', \n",
    "#visualize predictor look for outliers\n",
    "fig1=plt.figure()\n",
    "ax=fig1.add_subplot(1,1,1)\n",
    "ax.scatter(ftrain['left_eyebrow_outer_end_x'],ftrain['left_eyebrow_outer_end_y'],color=\"red\")\n",
    "ax.scatter(ftrain['right_eyebrow_outer_end_x'],ftrain['right_eyebrow_outer_end_y'],color=\"green\")\n",
    "ax.scatter(ftrain['nose_tip_x'],ftrain['nose_tip_y'], color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example image before stretching\n",
    "image_o=ftrain['Image'].iloc[0]\n",
    "image_o=image_o.split()\n",
    "image_o=np.array(image_o).reshape(96,96) # reshape to 96 x 96\n",
    "image_o=image_o.astype(float)  #float\n",
    "plt.matshow(image_o, fignum=100, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Example Image after stretching\n",
    "# Contrast stretching\n",
    "p5, p95 = np.percentile(image_o, (5, 95))\n",
    "img_rescale = exposure.rescale_intensity(image_o, in_range=(p5, p95))\n",
    "plt.matshow(img_rescale, fignum=100, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************************\n",
    "     Dimension Reduction\n",
    "********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################\n",
    "#    PCA\n",
    "###############################\n",
    "\n",
    "#pca\n",
    "pca_estimator  = RandomizedPCA(n_components=1400,whiten=True)#whiten=True parameter make it possible to project the data onto the \n",
    "#singular space while scaling each component to unit variance. \n",
    "\n",
    "#pca train\n",
    "x_train_pca = pca_estimator.fit_transform(x_train)#Fit the model with X and apply the dimensionality reduction on X.\n",
    "print(x_train_pca.shape)\n",
    "\n",
    "#pca test\n",
    "x_test_pca  = pca_estimator.transform(x_test)#Apply dimensionality reduction on X.\n",
    "print(x_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Identify Number of components to model\n",
    "#given Kaggle is about finding the highest score (versus most useful), we will define the elbow as 32 components.\n",
    "#However, given we are using Trees, it may not be useful to identify number of components.\n",
    "ex_var=pca_estimator.explained_variance_ratio_#reduce to 150 to visually see the elbow\n",
    "ex_var_all=pd.DataFrame(pca_estimator.explained_variance_ratio_)\n",
    "ex_var_all.to_csv(\"ex_var_all.csv\") \n",
    "plt.plot(ex_var)\n",
    "plt.xlabel('Component')\n",
    "plt.ylabel('Explained Variance in %')\n",
    "plt.title('Explained Variance by Component')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************************************\n",
    "Create Training, Test, and holdout sets\n",
    "***************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pca training and test sets for cross validation\n",
    "x_traincv_pca, x_testcv_pca, y_traincv_pca, y_testcv_pca = cross_validation.train_test_split(x_train_pca, \n",
    "                                                                             y_train, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training and test sets for cross validation\n",
    "x_traincv, x_testcv, y_traincv, y_testcv = cross_validation.train_test_split(x_train,y_train, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************\n",
    "Random Forest Regressor\n",
    "*****************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#Random Forest Parameter Selection#\n",
    "###################################\n",
    "#function to \n",
    "def rf_params(xt,yt):\n",
    "    param_grid ={\"max_features\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,\n",
    "                                  30,31,32,33,34,35,36,37,38],\n",
    "                 \"max_depth\" : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,\n",
    "                                32,33,34,35,36,38,39,40,41,42,43,44,45,46,47,48],\n",
    "                 \"min_samples_split\": [1,2,3,4,5,6,7,8],\n",
    "                 \"min_samples_leaf\" : [1,2,3,4,5,6,7,8],}\n",
    "\n",
    "    rf=RandomForestRegressor(n_jobs=-1, oob_score=True)\n",
    "\n",
    "    grid=RandomizedSearchCV(estimator=rf, param_distributions=param_grid,scoring=\"mean_squared_error\", \n",
    "                            n_jobs=-1, cv=5,n_iter=1000)\n",
    "\n",
    "    grid_train = grid.fit(xt,yt)\n",
    "\n",
    "    print(grid.best_params_)\n",
    "\n",
    "\n",
    "    \n",
    "#rf_params(xt=x_train,yt=y_train)\n",
    "rf_params(xt=x_testcv_pca,yt=y_testcv_pca)\n",
    "\n",
    "#32 components {'min_samples_leaf': 2, 'max_features': 14, 'max_depth': 43, 'min_samples_split': 2}\n",
    "#36 components {'min_samples_split': 4, 'max_features': 18, 'min_samples_leaf': 3, 'max_depth': 18}\n",
    "#39'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 18, 'max_depth': 44}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#  RandomForestRegressor        #\n",
    "#################################\n",
    "\n",
    "def rf_model(label,x_train,y_train,x_test,# y_test,\n",
    "             max_depth,max_features,min_samples_leaf,min_samples_split):\n",
    "\n",
    "    rf_model = RandomForestRegressor(n_estimators=11119,n_jobs=-1,oob_score = True, max_depth=max_depth,max_features=max_features,\n",
    "                                     min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split)\n",
    "    rf_model_fit = rf_model.fit(x_train, y_train)\n",
    "    y_pred_train = pd.DataFrame(rf_model_fit.predict(x_train))\n",
    "    y_pred_test  = pd.DataFrame(rf_model_fit.predict(x_test))\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train) \n",
    "#    mse_test  = mean_squared_error(y_test , y_pred_test)\n",
    "    print(\"train mse: \" + str(mse_train))\n",
    "#    print(\"test mse: \" + str(mse_test))\n",
    "\n",
    "    #create submission file\n",
    "    location_df=[]\n",
    "    location_df=pd.DataFrame(columns=['ImageId','FeatureName','Location'])\n",
    "    FeatureName_list=ftrain.columns[0:30]\n",
    "    i=0\n",
    "\n",
    "    for FName in FeatureName_list:\n",
    "        for z in range(len(ftest)):\n",
    "            sub_temp=pd.DataFrame({'ImageId':[ftest['ImageId'].iloc[z]],\n",
    "                              'FeatureName':[FName],\n",
    "                              'Location':[y_pred_test.ix[z,i:i].values]})\n",
    "            location_df=location_df.append(sub_temp)\n",
    "        i=i+1\n",
    "\n",
    "    Submission_df=pd.merge(flookup,location_df)\n",
    "    Submission_df=Submission_df.drop(['ImageId'],axis=1)\n",
    "    Submission_df=Submission_df.drop(['FeatureName'],axis=1)\n",
    "    Submission_df['Location']=Submission_df['Location'].astype(float)\n",
    "    Submission_df.to_csv(\"submission_\" + label + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mse: 0.696614577332\n"
     ]
    }
   ],
   "source": [
    "#original data\n",
    "rf_model(label=\"rf_over3\",x_train=x_train,y_train=y_train,x_test=x_test,\n",
    "         max_depth=50,max_features=2016,min_samples_leaf=1,min_samples_split=1)\n",
    "\n",
    "#{'min_samples_leaf': 3, 'max_depth': 42, 'max_features': 46, 'min_samples_split': 5}\n",
    "#{'max_depth': 39, 'max_features': 38, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
    "\n",
    "#{'max_depth': 30, 'max_features': 28, 'min_samples_split': 2, 'min_samples_leaf': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#original data 60% training set\n",
    "rf_model(label=\"rf_o_cv\",x_train=x_traincv,y_train=y_traincv,x_test=x_testcv, #y_test=y_testcv,\n",
    "         max_depth=42,max_features=46,min_samples_leaf=3,min_samples_split=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pca full training set\n",
    "rf_model(label=\"rf_pca_4_31_3_18\",x_train=x_train_pca,y_train=y_train,x_test=x_test_pca, #y_test=y_testcv,\n",
    "         max_depth=31,max_features=38,min_samples_leaf=3,min_samples_split=4)\n",
    "\n",
    "#{'min_samples_split': 4, 'max_depth': 31, 'min_samples_leaf': 3, 'max_features': 18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pca cross validation\n",
    "rf_model(label=\"rf_pca_cv\",x_train=x_traincv_pca,y_train=y_traincv_pca,x_test=x_testcv_pca, y_test=y_testcv_pca,\n",
    "         max_depth=31,max_features=38,min_samples_leaf=3,min_samples_split=4)\n",
    "\n",
    "#{'min_samples_split': 4, 'max_depth': 31, 'min_samples_leaf': 3, 'max_features': 18}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training and test sets for cross validation\n",
    "x_traincv, x_testcv, y_traincv, y_testcv = cross_validation.train_test_split(x_train,y_train, test_size=0.4, random_state=0)\n",
    "for i in range(15,50):\n",
    "    pca_estimator  = RandomizedPCA(n_components=i,whiten=True)\n",
    "    x_train_pca = pca_estimator.fit_transform(x_traincv)\n",
    "    x_test_pca  = pca_estimator.transform(x_testcv)\n",
    "    rf_model = RandomForestRegressor(n_estimators=1016,n_jobs=-1,max_depth=44,max_features=i,\n",
    "                                     min_samples_leaf=2,min_samples_split=2)\n",
    "#{'min_samples_leaf': 2, 'max_features': 14, 'max_depth': 43, 'min_samples_split': 2}\n",
    "#{'min_samples_split': 4, 'max_features': 18, 'min_samples_leaf': 3, 'max_depth': 18}\n",
    "#'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 18, 'max_depth': 44}\n",
    "#validation that 39 is optimal for number of components\n",
    "    rf_model_fit = rf_model.fit(x_train_pca, y_traincv)\n",
    "    y_pred_train = pd.DataFrame(rf_model_fit.predict(x_train_pca))\n",
    "    y_pred_test  = pd.DataFrame(rf_model_fit.predict(x_test_pca))\n",
    "    mse_train = mean_squared_error(y_traincv, y_pred_train)\n",
    "    mse_test = mean_squared_error(y_testcv, y_pred_test)\n",
    "    print(\"train mse: \" + str(mse_train) + \"test mse: \"+ str(mse_test)+ \"num comp: \"+ str(i))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************************\n",
    "Extra Trees Regressor()\n",
    "****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#Extra Trees   Parameter Selection#\n",
    "###################################\n",
    "#function to \n",
    "def et_params(xt,yt):\n",
    "    param_grid ={\"max_features\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,\n",
    "                                32,33,34,35,36,37,],\n",
    "                 \"max_depth\" : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,\n",
    "                                32,33,34,35,36,38,39,40,41,42,43,44,45,46,47,48],\n",
    "                 \"min_samples_split\": [1,2,3,4,5,6,7],\n",
    "                 \"min_samples_leaf\" : [1,2,3,4,5,6,7],}\n",
    "\n",
    "    rf=RandomForestRegressor()\n",
    "\n",
    "    grid=RandomizedSearchCV(estimator=rf, param_distributions=param_grid,scoring=\"mean_squared_error\", \n",
    "                            n_jobs=-1, cv=5,n_iter=1000)\n",
    "\n",
    "    grid_train = grid.fit(xt,yt)\n",
    "\n",
    "    print(grid.best_params_)\n",
    "\n",
    "#et_params(xt=x_train,yt=y_train)\n",
    "et_params(xt=x_train_pca,yt=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#  ExtraTreesRegressor     #\n",
    "############################\n",
    "\n",
    "et_model = ExtraTreesRegressor(n_estimators=4016,n_jobs=-1,max_depth=27, min_samples_split=3, \n",
    "                               max_features=18, min_samples_leaf=2)\n",
    "#{'min_samples_leaf': 2, 'max_features': 18, 'max_depth': 27, 'min_samples_split': 3}\n",
    "\n",
    "et_model_fit = et_model.fit(x_traincv_pca, y_traincv_pca)\n",
    "\n",
    "y_pred_train = pd.DataFrame(et_model_fit.predict(x_traincv_pca))\n",
    "\n",
    "y_pred_test  = pd.DataFrame(et_model_fit.predict(x_testcv_pca))\n",
    "\n",
    "mse_train = mean_squared_error(y_traincv_pca, y_pred_train) \n",
    "mse_test = mean_squared_error(y_testcv_pca, y_pred_test) \n",
    "\n",
    "print(\"train mse: \" + str(mse_train))\n",
    "print(\"test mse: \"  + str(mse_test))\n",
    "\n",
    "location_df=pd.DataFrame(columns=['ImageId','FeatureName','Location'])\n",
    "FeatureName_list=ftrain.columns[0:30]\n",
    "i=0\n",
    "for FName in FeatureName_list:\n",
    "    for z in range(len(ftest)):\n",
    "        sub_temp=pd.DataFrame({'ImageId':[ftest['ImageId'].iloc[z]],\n",
    "                              'FeatureName':[FName],\n",
    "                              'Location':[y_pred_test.ix[z,i:i].values]})\n",
    "        location_df=location_df.append(sub_temp)\n",
    "    i=i+1\n",
    "    \n",
    "Submission_df=pd.merge(flookup,location_df)\n",
    "Submission_df=Submission_df.drop(['ImageId'],axis=1)\n",
    "Submission_df=Submission_df.drop(['FeatureName'],axis=1)\n",
    "Submission_df['Location']=Submission_df['Location'].astype(float)\n",
    "\n",
    "Submission_df.to_csv(\"submission_et_pca_cv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************\n",
    "          Decision Tree\n",
    "******************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#Decision Tree Parameter Selection#\n",
    "###################################\n",
    "#function to \n",
    "def dt_params(xt,yt):\n",
    "    param_grid ={\"max_features\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,\n",
    "                                32,33,34,35,36,37,38],\n",
    "                 \"max_depth\" : [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,\n",
    "                                32,33,34,35,36,38,39,40,41,42,43,44,45,46,47,48],\n",
    "                 \"min_samples_split\": [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "                 \"min_samples_leaf\": [1,2,3,4,5,6,7,8,9,10,11,12],}\n",
    "\n",
    "    rf=DecisionTreeRegressor()\n",
    "\n",
    "    grid=RandomizedSearchCV(estimator=rf, param_distributions=param_grid,scoring=\"mean_squared_error\", \n",
    "                            n_jobs=-1, cv=5,n_iter=1000)\n",
    "\n",
    "    grid_train = grid.fit(xt,yt)\n",
    "\n",
    "    print(grid.best_params_)\n",
    "\n",
    "dt_params(xt=x_train,yt=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtr_model = DecisionTreeRegressor(max_features=18, min_samples_split=2,max_depth=44,min_samples_leaf=1)\n",
    "#{'max_depth': 44, 'max_features': 38, 'min_samples_split': 4, 'min_samples_leaf': 12}\n",
    "\n",
    "dtr_model_fit = dtr_model.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train = pd.DataFrame(dtr_model_fit.predict(x_train))\n",
    "\n",
    "y_pred_test  = pd.DataFrame(dtr_model_fit.predict(x_test))\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(mse_train)\n",
    "\n",
    "\n",
    "location_df=pd.DataFrame(columns=['ImageId','FeatureName','Location'])\n",
    "FeatureName_list=ftrain.columns[0:30]\n",
    "i=0\n",
    "for FName in FeatureName_list:\n",
    "    for z in range(len(ftest)):\n",
    "        sub_temp=pd.DataFrame({'ImageId':[ftest['ImageId'].iloc[z]],\n",
    "                              'FeatureName':[FName],\n",
    "                              'Location':[y_pred_test.ix[z,i:i].values]})\n",
    "        location_df=location_df.append(sub_temp)\n",
    "    i=i+1\n",
    "    \n",
    "Submission_df=pd.merge(flookup,location_df)\n",
    "Submission_df=Submission_df.drop(['ImageId'],axis=1)\n",
    "Submission_df=Submission_df.drop(['FeatureName'],axis=1)\n",
    "Submission_df['Location']=Submission_df['Location'].astype(float)\n",
    "\n",
    "Submission_df.to_csv(\"submission_dtreg_default.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
